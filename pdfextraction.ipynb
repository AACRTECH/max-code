{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymupdf\n",
    "import pdfplumber\n",
    "import re\n",
    "import os\n",
    "import spacy\n",
    "\n",
    "#focus on results and discussion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = r\"C:\\Users\\maxwell.bicking\\OneDrive - American Association for Cancer Res\\Desktop\\GENIEpdfs\\Chen-2019.pdf\"\n",
    "\n",
    "everything_file_path = r\"C:\\Users\\maxwell.bicking\\OneDrive - American Association for Cancer Res\\Desktop\\pdfOutputs\\pdfextractall.txt\"\n",
    "\n",
    "output_file_path = r\"C:\\Users\\maxwell.bicking\\OneDrive - American Association for Cancer Res\\Desktop\\pdfOutputs\\pdfextractdiscussion.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracts everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete text has been saved to C:\\Users\\maxwell.bicking\\OneDrive - American Association for Cancer Res\\Desktop\\pdfOutputs\\pdfextractall.txt\n"
     ]
    }
   ],
   "source": [
    "doc = pymupdf.open(pdf_file_path)\n",
    "\n",
    "# Initialize an empty string to store the text\n",
    "text = \"\"\n",
    "\n",
    "# Loop through all pages and extract text\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num)\n",
    "    text += page.get_text(\"text\")  # Extract the text from each page\n",
    "\n",
    "# Close the PDF\n",
    "doc.close()\n",
    "\n",
    "# Write the complete text to a .txt file\n",
    "with open(everything_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(text)\n",
    "\n",
    "print(f\"Complete text has been saved to {everything_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracts only the Results section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final section has been saved to C:\\Users\\maxwell.bicking\\OneDrive - American Association for Cancer Res\\Desktop\\pdfOutputs\\pdfextractdiscussion.txt\n"
     ]
    }
   ],
   "source": [
    "# This is the best result so far\n",
    "\n",
    "# Function to clean the extracted text, can be greatly improved\n",
    "def clean_text(text):\n",
    "    # Remove URLs (http/https/ftp) and email addresses\n",
    "    text = re.sub(r'http\\S+|www\\S+|mailto:\\S+|\\S+@\\S+', '', text)\n",
    "    text = ' '.join(text.split())  # Remove excessive whitespace\n",
    "    return text\n",
    "\n",
    "# Function to extract the final section based on headings and stop at any new heading\n",
    "def extract_final_section(text):\n",
    "    # Define common section headings to start extraction\n",
    "    start_headings = [\n",
    "        \"conclusion\", \"conclusions\", \"discussion\", \"results\", \n",
    "        \"summary\", \"final remarks\", \"closing thoughts\"\n",
    "    ]\n",
    "    \n",
    "    # Regular expression to detect any heading (common format: capitalized words or followed by a colon/newline)\n",
    "    heading_pattern = re.compile(r'\\b[A-Z][A-Za-z\\s]+(:|\\n)', re.MULTILINE)\n",
    "\n",
    "    # Case-insensitive search for the start heading\n",
    "    start_pos = None\n",
    "    for heading in start_headings:\n",
    "        match = re.search(rf\"\\b{heading}\\b\", text, re.IGNORECASE)\n",
    "        if match:\n",
    "            start_pos = match.start()\n",
    "            break\n",
    "    \n",
    "    # If no start heading is found, return a default message or the entire text\n",
    "    if start_pos is None:\n",
    "        return \"Relevant section not found.\"\n",
    "\n",
    "    # Find the next heading after the start position\n",
    "    end_pos = None\n",
    "    for match in heading_pattern.finditer(text[start_pos:]):\n",
    "        heading_text = match.group().strip().lower()\n",
    "        # Stop at any heading that is **not** a start heading\n",
    "        if not any(h in heading_text for h in start_headings):\n",
    "            end_pos = start_pos + match.start()\n",
    "            break\n",
    "\n",
    "    # Extract the relevant section, stopping at the first unwanted heading\n",
    "    if end_pos:\n",
    "        return text[start_pos:end_pos]\n",
    "    else:\n",
    "        return text[start_pos:]  # If no end heading is found, return till the end of the text\n",
    "\n",
    "# Open the pdf\n",
    "doc = pymupdf.open(pdf_file_path)\n",
    "\n",
    "# Initialize an empty string to store the text\n",
    "text = \"\"\n",
    "\n",
    "# Loop through all pages and extract text\n",
    "for page_num in range(doc.page_count):\n",
    "    page = doc.load_page(page_num)\n",
    "    text += page.get_text(\"text\")  # Extract the text from each page\n",
    "\n",
    "# Clean the extracted text\n",
    "cleaned_text = clean_text(text)\n",
    "\n",
    "# Extract only the final section\n",
    "final_section = extract_final_section(cleaned_text)\n",
    "\n",
    "# Write the final section to a .txt file\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(final_section)\n",
    "\n",
    "# Close the pdf\n",
    "doc.close()\n",
    "\n",
    "print(f\"Final section has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_text = r\"We also found that the recurrently mutated genes in our study were similar to TCGA and Li et al., and the overlap between these three studies is about 50% (Supplementary Fig.Â S1B,C). Some cancer-related genes that\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(free_text)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n",
      "File \u001b[1;32mc:\\Users\\maxwell.bicking\\AppData\\Local\\anaconda3\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maxwell.bicking\\AppData\\Local\\anaconda3\\lib\\site-packages\\spacy\\util.py:471\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m load_model_from_path(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m--> 471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en\")\n",
    "doc = nlp(free_text)\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spacy_version': '3.7.6',\n",
       " 'location': 'c:\\\\Users\\\\maxwell.bicking\\\\AppData\\\\Local\\\\anaconda3\\\\lib\\\\site-packages\\\\spacy',\n",
       " 'platform': 'Windows-10-10.0.22631-SP0',\n",
       " 'python_version': '3.10.9',\n",
       " 'pipelines': {}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Extract_Date\"] = os.root.basename"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
